{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy.stats as sci\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.ticker as mtick\n",
    "import copy as cpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6453\n"
     ]
    }
   ],
   "source": [
    "# import sentiments as dictionary using re\n",
    "file = open('NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', 'r').read()\n",
    "pattern = r'(\\w*)\\s*(\\w*)\\s*(\\d)'\n",
    "sentiments = {}\n",
    "\n",
    "for word in re.findall(pattern, file):\n",
    "    if int(word[2]) == 1:\n",
    "        if word[0] in sentiments.keys():\n",
    "            sentiments[word[0]].append(word[1])\n",
    "        else: \n",
    "            sentiments[word[0]] = [word[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis function\n",
    "'''\n",
    "json_object_structure = [{\n",
    "    'time': str,\n",
    "    'text': str, \n",
    "    'count': int,\n",
    "    'sentiments' : {\n",
    "        'sentiment': {\n",
    "            'p':float, \n",
    "            'words': set[str]\n",
    "        },\n",
    "        'sentiment1': {\n",
    "            'p':float, \n",
    "            'words': set[str]\n",
    "        },\n",
    "        'sentiment2': {\n",
    "            'p':float, \n",
    "            'words':set[str]\n",
    "        },\n",
    "    }\n",
    "}]\n",
    "'''\n",
    "# import chunks of text from transcripts and get sentiments\n",
    "def sentiment_analysis(path: str, out:str, s_filters:list[str] or None = False, w_filters: list[str] or None = [], ):\n",
    "    file = open(path, 'r')\n",
    "    analysis = [] # output list of objects\n",
    "    total = {} # words w/ sentiment in transcript\n",
    "    t_count = 0 # total number of words w/ sentiment in entire transcript\n",
    "    pattern = r'\\b(\\d+:\\d+)\\s*,\\s*(\\w+)\\s*,\\s*\\\"*(.*)\\\"*,*\\n' # [time, name, text]\n",
    "    for line in re.findall(pattern, file.read()):\n",
    "        t_sentiments = {} # sentiment list for each paragraph \n",
    "        count = 0 # number of words w/ sentiment found in exerpt \n",
    "\n",
    "        # separate each word\n",
    "        for word in re.findall(r'[\\w\\'\\-]+', line[2]):\n",
    "            if word in sentiments.keys() and word not in w_filters:\n",
    "                count += 1\n",
    "                # if word indicates sentiment count in dict\n",
    "                for sentiment in sentiments[word]:\n",
    "                    if sentiment not in t_sentiments.keys():\n",
    "                        t_sentiments[sentiment] = {'p' : 1, 'words' : {word}}\n",
    "                    else:\n",
    "                        t_sentiments[sentiment]['p'] += 1\n",
    "                        t_sentiments[sentiment]['words'].add(word)\n",
    "            \n",
    "        if s_filters: \n",
    "            # add totals to total list | no filter\n",
    "                t_count += count\n",
    "                for key in t_sentiments.keys():\n",
    "                    if line[1] not in s_filters:\n",
    "                        if key not in total.keys():\n",
    "                            total[key] = {'p' : t_sentiments[key]['p'], 'words' : cpy.deepcopy(t_sentiments[key]['words'])}\n",
    "                        else:\n",
    "                            total[key]['p'] += t_sentiments[key]['p']\n",
    "                            total[key]['words'] = list(t_sentiments[key]['words'].union(total[key]['words']))\n",
    "                        # get proportion from total counts\n",
    "                        t_sentiments[key]['p'] = t_sentiments[key]['p'] / count\n",
    "                    t_sentiments[key]['words'] = list(t_sentiments[key]['words'])\n",
    "        else: \n",
    "                # add totals to total list | no filter\n",
    "                t_count += count\n",
    "                for key in t_sentiments.keys():\n",
    "                    if key not in total.keys():\n",
    "                        total[key] = {'p' : t_sentiments[key]['p'], 'words' : cpy.deepcopy(t_sentiments[key]['words'])}\n",
    "                    else:\n",
    "                        total[key]['p'] += t_sentiments[key]['p']\n",
    "                        total[key]['words'] = list(t_sentiments[key]['words'].union(total[key]['words']))\n",
    "                    # get proportion from total counts\n",
    "                    t_sentiments[key]['words'] = list(t_sentiments[key]['words'])\n",
    "                    t_sentiments[key]['p'] = t_sentiments[key]['p'] / count\n",
    "                \n",
    "\n",
    "        analysis.append({\n",
    "                        'speaker' : line[1],\n",
    "                        'time' : line[0],\n",
    "                        'text': line[2],\n",
    "                        'count' : count,\n",
    "                        'sentiments' : t_sentiments})\n",
    "        \n",
    "    # get total proportions \n",
    "    for key in total.keys():\n",
    "        total[key]['p'] = total[key]['p'] / t_count\n",
    "        total[key]['words'] = list(total[key]['words'])\n",
    "\n",
    "    total['count'] = t_count\n",
    "\n",
    "    analysis.append(total)\n",
    "    file.close()\n",
    "    file = open(out, 'w')\n",
    "    json.dump(analysis, file)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all file names and generate analysis \n",
    "path = os.getcwd() + '\\\\transcripts'\n",
    "transcripts = os.listdir(path)\n",
    "pattern = r'(.+)\\.csv'\n",
    "s_filt = [\"Researcher 1\", \"Researcher 2\"]\n",
    "w_filt = [\"homelessness\", \"homeless\"]\n",
    "analysis = []\n",
    "for transcript in transcripts:\n",
    "    sentiment_analysis('transcripts\\\\' +  transcript,'analysis\\\\' +  re.findall(pattern, transcript)[0] + '.json', s_filters = s_filt , w_filters=w_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all *.json in analysis folder to a list\n",
    "path = os.getcwd() + '\\\\analysis'\n",
    "a_paths = os.listdir(path)\n",
    "analysis = []\n",
    "for a_path in a_paths: \n",
    "    if a_path[-5:] == '.json':\n",
    "        file = open(path + '\\\\' + a_path, 'r')\n",
    "        try:\n",
    "            analysis.append(json.load(file))\n",
    "            file.close()\n",
    "        except:\n",
    "            print(a_path,\"Cannot be parsed\", file.read())\n",
    "            file.close()\n",
    "\n",
    "vr_filter = np.array([True, True, True, True, False, False, False, False, False, False, True, True, True, True,])\n",
    "pre_filter = np.array([False, True, False, True, False, True, False, True, False, True, False, True, False, True,])\n",
    "\n",
    "anger = np.array([sample[-1]['anger']['p'] if 'anger' in sample[-1].keys() else 0 for sample in analysis ])\n",
    "anticipation = np.array([sample[-1]['anticipation']['p'] if 'anticipation' in sample[-1].keys() else 0 for sample in analysis ])\n",
    "disgust = np.array([sample[-1]['disgust']['p'] if 'disgust' in sample[-1].keys() else 0 for sample in analysis ])\n",
    "fear = np.array([sample[-1]['fear']['p'] if 'fear' in sample[-1].keys() else 0 for sample in analysis ])\n",
    "joy = np.array([sample[-1]['joy']['p'] if 'joy' in sample[-1].keys() else 0 for sample in analysis ])\n",
    "negative = np.array([sample[-1]['negative']['p'] if 'negative' in sample[-1].keys() else 0 for sample in analysis ])\n",
    "positive = np.array([sample[-1]['positive']['p'] if 'positive' in sample[-1].keys() else 0 for sample in analysis ])\n",
    "sadness = np.array([sample[-1]['sadness']['p'] if 'sadness' in sample[-1].keys() else 0 for sample in analysis ])\n",
    "suprise = np.array([sample[-1]['suprise']['p'] if 'suprise' in sample[-1].keys() else 0 for sample in analysis ])\n",
    "trust = np.array([sample[-1]['trust']['p'] if 'trust' in sample[-1].keys() else 0 for sample in analysis ])\n",
    "\n",
    "counts = np.array([sample[-1]['count'] for sample in analysis ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter values and calculate pre-post difference \n",
    "# pre-sentiment values of 0 were replaced with arbitrary value of 1% \n",
    "d_emotions = {}\n",
    "ttests = {}\n",
    "post_anger = anger[~pre_filter]\n",
    "pre_anger = anger[pre_filter]\n",
    "pre_anger[pre_anger == 0] = np.mean(pre_anger) \n",
    "d_emotions[\"Anger\"] = (post_anger - pre_anger) / pre_anger\n",
    "ttests[\"Anger\"] = sci.ttest_1samp(post_anger, np.mean(anger))\n",
    "\n",
    "post_anticipation = anticipation[~pre_filter]\n",
    "pre_anticipation = anticipation[pre_filter]\n",
    "pre_anticipation[pre_anticipation == 0] = np.mean(pre_anticipation) \n",
    "d_emotions[\"Anticipation\"] = (post_anticipation - pre_anticipation) / pre_anticipation\n",
    "ttests[\"Anticipation\"] = sci.ttest_1samp(post_anticipation, np.mean(anticipation))\n",
    "\n",
    "post_disgust = disgust[~pre_filter]\n",
    "pre_disgust = disgust[pre_filter]\n",
    "pre_disgust[pre_disgust == 0] = np.mean(pre_disgust) \n",
    "d_emotions[\"Disgust\"] = (post_disgust - pre_disgust) / pre_anticipation\n",
    "ttests[\"Disgust\"] = sci.ttest_1samp(post_disgust, np.mean(disgust))\n",
    "\n",
    "post_fear = fear[~pre_filter]\n",
    "pre_fear = fear[pre_filter]\n",
    "pre_fear[pre_fear == 0] = np.mean(pre_fear) \n",
    "d_emotions[\"Fear\"] = (post_fear - pre_fear) / pre_fear\n",
    "ttests[\"Fear\"] = sci.ttest_1samp(post_fear, np.mean(fear))\n",
    "\n",
    "post_joy = joy[~pre_filter]\n",
    "pre_joy = joy[pre_filter]\n",
    "pre_joy[pre_joy == 0] = np.mean(pre_joy) \n",
    "d_emotions[\"Joy\"] = (post_joy - pre_joy) / pre_joy\n",
    "ttests[\"Joy\"] = sci.ttest_1samp(post_joy, np.mean(joy))\n",
    "\n",
    "\n",
    "post_sadness = sadness[~pre_filter]\n",
    "pre_sadness = sadness[pre_filter]\n",
    "pre_sadness[pre_sadness == 0] = np.mean(pre_sadness) \n",
    "d_emotions[\"Sadness\"] = (post_sadness - pre_sadness) / pre_sadness\n",
    "ttests[\"Sadness\"] = sci.ttest_1samp(post_sadness, np.mean(sadness))\n",
    "\n",
    "post_trust = trust[~pre_filter]\n",
    "pre_trust = trust[pre_filter]\n",
    "pre_trust[pre_trust == 0] = np.mean(pre_trust) \n",
    "d_emotions[\"Trust\"] = (post_trust - pre_trust) / pre_trust\n",
    "ttests[\"Trust\"] = sci.ttest_1samp(post_trust, np.mean(trust))\n",
    "\n",
    "post_negative = negative[~pre_filter]\n",
    "pre_negative = negative[pre_filter]\n",
    "pre_negative[pre_negative == 0] = np.mean(pre_negative) \n",
    "d_emotions[\"Negative\"] = (post_negative - pre_negative) / pre_negative\n",
    "ttests[\"Negative\"] = sci.ttest_1samp(post_negative, np.mean(negative))\n",
    "\n",
    "post_positive = positive[~pre_filter]\n",
    "pre_positive = positive[pre_filter]\n",
    "pre_positive[pre_positive == 0] = np.mean(pre_positive) \n",
    "d_emotions[\"Positive\"] = (post_positive - pre_positive) / pre_positive\n",
    "ttests[\"Positive\"] = sci.ttest_1samp(post_positive, np.mean(positive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables of statistics\n",
    "pseudonyms = np.array(['Anika','Jack', 'James', 'Ashlynn', 'Eevi', 'Maggi', 'Ray'])\n",
    "\n",
    "# % Δ Emotion Proportion Between Pre and Post Interview\n",
    "t_row = np.insert(pseudonyms, [0, len(pseudonyms)], ['Emotion', 'Mean'])\n",
    "emo_column = np.array([key for key, value in d_emotions.items()], dtype=\"str_\")\n",
    "mean_column = np.array([np.mean(value) for key, value in d_emotions.items()])\n",
    "vr_vid_row = np.array(['VR' if filt else 'Video' for filt in vr_filter[::2]])\n",
    "table = np.stack([value for key, value in d_emotions.items()])\n",
    "table = np.vstack([table.T, mean_column]).T\n",
    "\n",
    "np.savetxt(\"analysis/emotion_change/values.csv\", table, delimiter=\",\", fmt='%.4f')\n",
    "np.savetxt(\"analysis/emotion_change/emotion_column.csv\", emo_column, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"analysis/emotion_change/t_row.csv\", t_row, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"analysis/emotion_change/vr_vid_row.csv\", vr_vid_row, delimiter=\",\", fmt='%s')\n",
    "\n",
    "# Mean % Δ Emotion Proportion Between Pre and Post Interview by VR vs Video\n",
    "vr_vid_means = {'VR': np.array([]), 'Video': np.array([])}\n",
    "for emotion, values in d_emotions.items():\n",
    "    vr_vid_means['VR'] = np.append(vr_vid_means['VR'], np.mean(values[vr_filter[::2]]))\n",
    "    vr_vid_means['Video'] = np.append(vr_vid_means['Video'], np.mean(values[~vr_filter[::2]]))\n",
    "\n",
    "table = np.stack([vr_vid_means['VR'] , vr_vid_means['Video']])\n",
    "t_row = emo_column\n",
    "\n",
    "np.savetxt(\"analysis/vr_v_vid/values.csv\", table, delimiter=',')\n",
    "np.savetxt(\"analysis/vr_v_vid/t_row.csv\", t_row, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"analysis/vr_v_vid/l_col.csv\", np.array(['VR', 'Video']), delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttest for post counts TtestResult(statistic=0.9349657893692583, pvalue=0.385890433105174, df=6)\n"
     ]
    }
   ],
   "source": [
    "# ttests for count of emotionally charged \n",
    "post_count = counts[~pre_filter]\n",
    "print('ttest for post counts',sci.ttest_1samp(post_count, np.mean(counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs for pre vs post emotions\n",
    "colors = ['red', 'cyan', 'limegreen', 'orchid', 'gold', 'blue', 'purple', 'black', 'green']\n",
    "\n",
    "# Graph of individual\n",
    "x = np.arange(len(pseudonyms))\n",
    "width = 0.08\n",
    "multi = 0\n",
    "\n",
    "fig, ax = pl.subplots(layout='constrained')\n",
    "\n",
    "for emotion, values in d_emotions.items():\n",
    "    offset = width * multi\n",
    "    rects = ax.bar(x + offset, values, width, label=emotion, color=colors[multi])\n",
    "    multi += 1\n",
    "\n",
    "ax.set_ylabel(u'% Δ Emotion Proportion')\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax.set_xlabel('Participants')\n",
    "ax.set_title(u'Individual % Δ Emotion Proportion Between Pre and Post Interview')\n",
    "ax.legend()\n",
    "ax.set_xticks(x + width, pseudonyms)\n",
    "\n",
    "pl.show()\n",
    "pl.clf()\n",
    "\n",
    "# graph of means \n",
    "ax = pl.axes()\n",
    "emo_labels = []\n",
    "multi = 0\n",
    "\n",
    "for emotion, values in d_emotions.items():\n",
    "    ax.bar(emotion, np.mean(values), label = emotion, color=colors[multi])\n",
    "    emo_labels.append(emotion)\n",
    "    multi+=1\n",
    "\n",
    "emo_labels = np.array(emo_labels)\n",
    "\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax.set_xticklabels(emo_labels, rotation=45, ha='right')\n",
    "ax.set_title(u'Mean % Δ Emotion Proportion Between Pre and Post Interview')\n",
    "ax.set_ylabel(u'Δ Emotion Proportion')\n",
    "ax.set_xlabel('Emotion')\n",
    "\n",
    "pl.show()\n",
    "pl.clf()\n",
    "\n",
    "# means by VR vs Video\n",
    "x = np.arange(len(emo_labels))\n",
    "width = 0.3\n",
    "multi = 0\n",
    "\n",
    "fig, ax = pl.subplots(layout='constrained')\n",
    "\n",
    "colors = ['teal', 'maroon']\n",
    "for vr_vid, values in vr_vid_means.items():\n",
    "    offset = width * multi\n",
    "    rects = ax.bar(x + offset, values, width, label=vr_vid, color=colors[multi])\n",
    "    multi += 1\n",
    "\n",
    "ax.set_ylabel(u'% Δ Emotion Proportion')\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax.set_xlabel('Participants')\n",
    "ax.set_title(u'Mean % Δ Emotion Proportion Between Pre and Post Interview by Method of Consumption')\n",
    "ax.legend()\n",
    "ax.set_xticks(x + width, emo_labels)\n",
    "ax.set_xticklabels(emo_labels, rotation=45, ha='right')\n",
    "\n",
    "pl.show()\n",
    "pl.clf()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
